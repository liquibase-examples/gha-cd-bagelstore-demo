template:
  name: Coordinated DB and App Deployment
  identifier: Coordinated_DB_App_Deployment
  versionLabel: v1.0
  type: StepGroup
  projectIdentifier: bagel_store_demo
  orgIdentifier: default
  tags:
    purpose: coordinated_deployment
    components: database_application
  description: |
    Reusable step group for deploying database changes and application updates.
    Supports both AWS (RDS + App Runner) and Local (Docker Compose) deployment modes.

    Steps:
    1. Fetch Changelog Artifact - Downloads changelog zip from GitHub Packages
    2. Update Database - Runs Liquibase update via Docker container
    3. Deploy Application - Updates App Runner (AWS) or Docker Compose (Local)
    4. Health Check - Verifies deployment success with version check
    5. Fetch Instances - Reports instance information to Harness for tracking

    Environment variables used (automatically resolved from stage context):
    - env.variables.environment: Target environment (dev/test/staging/prod)
    - env.variables.demo_id: Demo instance identifier
    - env.variables.jdbc_url: Database connection URL
    - env.variables.rds_address: RDS endpoint address
    - env.variables.rds_port: RDS port
    - env.variables.database_name: Database name
    - env.variables.app_runner_service_arn: App Runner service ARN
    - env.variables.app_runner_service_url: App Runner service URL
    - env.variables.liquibase_flows_bucket: S3 bucket for flow files
    - env.variables.aws_region: AWS region

    Pipeline variables used:
    - pipeline.variables.VERSION: Git tag version to deploy
    - pipeline.variables.GITHUB_ORG: GitHub organization name

    Deployment mode controlled by:
    - DEPLOYMENT_TARGET environment variable: "aws" (default) or "local"

  spec:
    steps:
      # Step 1: Fetch changelog artifact from GitHub Packages
      - step:
          type: ShellScript
          name: Fetch Changelog Artifact
          identifier: Fetch_Changelog_Artifact
          spec:
            shell: Bash
            executionTarget: {}
            source:
              type: Inline
              spec:
                script: |-
                  #!/bin/bash
                  set -e

                  echo "=== Fetching Changelog Artifact ==="
                  echo "Version: <+pipeline.variables.VERSION>"
                  echo "GitHub Org: <+pipeline.variables.GITHUB_ORG>"

                  # Create working directory
                  mkdir -p /tmp/changelog
                  cd /tmp/changelog

                  # Download changelog zip from GitHub Packages
                  # Note: GitHub Packages uses Maven format for generic packages
                  PACKAGE_URL="https://maven.pkg.github.com/<+pipeline.variables.GITHUB_ORG>/harness-gha-bagelstore/bagel-store-changelog/<+pipeline.variables.VERSION>/bagel-store-changelog-<+pipeline.variables.VERSION>.zip"

                  echo "Downloading from: $PACKAGE_URL"

                  curl -L \
                    -H "Authorization: token <+secrets.getValue('github_pat')>" \
                    -o changelog.tar.gz \
                    "$PACKAGE_URL"

                  # Extract changelog
                  tar -xzf changelog.tar.gz

                  echo "Changelog extracted successfully"
                  ls -la
            environmentVariables: []
            outputVariables: []
          timeout: 5m

      # Step 2: Update database with Liquibase using S3 Flow Files
      - step:
          type: ShellScript
          name: Update Database
          identifier: Update_Database
          spec:
            shell: Bash
            executionTarget: {}
            source:
              type: Inline
              spec:
                script: |-
                  #!/bin/bash
                  set -e

                  echo "=== Updating Database with Liquibase Flow ==="
                  echo "Environment: <+env.variables.environment>"
                  echo "Deployment Target: ${DEPLOYMENT_TARGET:-aws}"
                  echo "Demo ID: <+env.variables.demo_id>"

                  # Determine deployment target (default to 'aws' if not set)
                  DEPLOYMENT_TARGET="${DEPLOYMENT_TARGET:-aws}"

                  if [ "$DEPLOYMENT_TARGET" = "aws" ]; then
                    # ===== AWS MODE - Use S3 Flow Files =====
                    echo "Using AWS RDS endpoint: <+env.variables.rds_endpoint>"
                    echo "Flow file: s3://<+env.variables.liquibase_flows_bucket>/main-deployment-flow.yaml"

                    docker run --rm \
                      -v /tmp/changelog:/liquibase/changelog \
                      -e AWS_ACCESS_KEY_ID=<+secrets.getValue('aws_access_key_id')> \
                      -e AWS_SECRET_ACCESS_KEY=<+secrets.getValue('aws_secret_access_key')> \
                      -e AWS_REGION=<+env.variables.aws_region> \
                      -e LIQUIBASE_LICENSE_KEY=<+secrets.getValue('liquibase_license_key')> \
                      -e LIQUIBASE_COMMAND_URL=<+env.variables.jdbc_url> \
                      -e LIQUIBASE_COMMAND_USERNAME='${awsSecretsManager:<+env.variables.demo_id>/rds/username}' \
                      -e LIQUIBASE_COMMAND_PASSWORD='${awsSecretsManager:<+env.variables.demo_id>/rds/password}' \
                      -e LIQUIBASE_COMMAND_CHANGELOG_FILE=changelog-master.yaml \
                      -e LIQUIBASE_COMMAND_CHECKS_SETTINGS_FILE=s3://<+env.variables.liquibase_flows_bucket>/liquibase.checks-settings.conf \
                      -w /liquibase/changelog \
                      liquibase/liquibase-secure:5.0.1 \
                      flow \
                      --flow-file=s3://<+env.variables.liquibase_flows_bucket>/main-deployment-flow.yaml

                  else
                    # ===== LOCAL MODE - Use Local Flow Files =====
                    echo "Using local PostgreSQL container: postgres-<+env.variables.environment>"
                    echo "Note: Local mode uses direct update, not flow files"

                    # Connect to Docker Compose network
                    docker run --rm \
                      --network harness-gha-bagelstore_bagel-network \
                      -v /tmp/changelog:/liquibase/changelog \
                      -e LIQUIBASE_LICENSE_KEY=<+secrets.getValue('liquibase_license_key')> \
                      liquibase/liquibase-secure:5.0.1 \
                      --url=jdbc:postgresql://postgres-<+env.variables.environment>:5432/<+env.variables.environment> \
                      --username=postgres \
                      --password=postgres \
                      --changeLogFile=changelog-master.yaml \
                      --log-level=INFO \
                      update
                  fi

                  echo "✅ Database update completed successfully"
            environmentVariables: []
            outputVariables: []
          timeout: 10m

      # Step 3: Deploy application to App Runner or Docker Compose
      - step:
          type: ShellScript
          name: Deploy Application
          identifier: Deploy_Application
          spec:
            shell: Bash
            executionTarget: {}
            source:
              type: Inline
              spec:
                script: |-
                  #!/bin/bash
                  set -e

                  echo "=== Deploying Application ==="
                  echo "Environment: <+env.variables.environment>"
                  echo "Version: <+pipeline.variables.VERSION>"
                  echo "Deployment Target: ${DEPLOYMENT_TARGET:-aws}"

                  # Determine deployment target (default to 'aws' if not set)
                  DEPLOYMENT_TARGET="${DEPLOYMENT_TARGET:-aws}"

                  if [ "$DEPLOYMENT_TARGET" = "aws" ]; then
                    # ===== AWS MODE =====
                    echo "Deploying to App Runner"

                    export AWS_ACCESS_KEY_ID=<+secrets.getValue('aws_access_key_id')>
                    export AWS_SECRET_ACCESS_KEY=<+secrets.getValue('aws_secret_access_key')>
                    export AWS_DEFAULT_REGION=<+env.variables.aws_region>

                    SERVICE_ARN="<+env.variables.app_runner_service_arn>"

                    aws apprunner update-service \
                      --service-arn "$SERVICE_ARN" \
                      --source-configuration "{
                        \"ImageRepository\": {
                          \"ImageIdentifier\": \"ghcr.io/<+pipeline.variables.GITHUB_ORG>/bagel-store:<+pipeline.variables.VERSION>\",
                          \"ImageRepositoryType\": \"ECR_PUBLIC\",
                          \"ImageConfiguration\": {
                            \"Port\": \"5000\",
                            \"RuntimeEnvironmentVariables\": {
                              \"DATABASE_URL\": \"postgresql://\${awsSecretsManager:<+env.variables.demo_id>/rds/username}:\${awsSecretsManager:<+env.variables.demo_id>/rds/password}@<+env.variables.rds_address>:<+env.variables.rds_port>/<+env.variables.database_name>\",
                              \"FLASK_ENV\": \"production\",
                              \"APP_VERSION\": \"<+pipeline.variables.VERSION>\"
                            }
                          }
                        }
                      }" \
                      --region <+env.variables.aws_region>

                  else
                    # ===== LOCAL MODE =====
                    echo "Deploying to Docker Compose"

                    # Navigate to repository root
                    cd $HOME/workspace/harness-gha-bagelstore

                    # Ensure .env file exists
                    if [ ! -f .env ]; then
                      echo "Creating .env from template"
                      cp .env.example .env
                    fi

                    # Update version in .env file
                    ENV_UPPER=$(echo "<+env.variables.environment>" | tr '[:lower:]' '[:upper:]')
                    ENV_VAR="VERSION_${ENV_UPPER}"
                    NEW_VERSION="<+pipeline.variables.VERSION>"

                    echo "Updating ${ENV_VAR}=${NEW_VERSION} in .env"

                    if grep -q "^${ENV_VAR}=" .env; then
                      # Update existing line (macOS compatible)
                      sed -i.bak "s/^${ENV_VAR}=.*/${ENV_VAR}=${NEW_VERSION}/" .env
                      rm -f .env.bak
                    else
                      # Add new line
                      echo "${ENV_VAR}=${NEW_VERSION}" >> .env
                    fi

                    # Show current .env state
                    echo "Current .env configuration:"
                    grep "^VERSION_" .env || echo "No VERSION variables found"

                    # Pull new image version
                    docker compose -f docker-compose-demo.yml pull app-<+env.variables.environment>

                    # Restart specific service with new version
                    docker compose -f docker-compose-demo.yml up -d --no-deps app-<+env.variables.environment>
                  fi

                  echo "✅ Application deployment completed"
            environmentVariables: []
            outputVariables:
              - name: SERVICE_URL
                type: String
                value: service_url
          timeout: 10m

      # Step 4: Health check
      - step:
          type: ShellScript
          name: Health Check
          identifier: Health_Check
          spec:
            shell: Bash
            executionTarget: {}
            source:
              type: Inline
              spec:
                script: |-
                  #!/bin/bash
                  set -e

                  echo "=== Performing Health Check ==="
                  echo "Deployment Target: ${DEPLOYMENT_TARGET:-aws}"

                  # Determine deployment target (default to 'aws' if not set)
                  DEPLOYMENT_TARGET="${DEPLOYMENT_TARGET:-aws}"

                  if [ "$DEPLOYMENT_TARGET" = "aws" ]; then
                    # ===== AWS MODE =====
                    SERVICE_URL="<+env.variables.app_runner_service_url>"
                    HEALTH_URL="https://${SERVICE_URL}/health"
                    VERSION_URL="https://${SERVICE_URL}/version"
                  else
                    # ===== LOCAL MODE =====
                    case "<+env.variables.environment>" in
                      dev)     PORT=5001 ;;
                      test)    PORT=5002 ;;
                      staging) PORT=5003 ;;
                      prod)    PORT=5004 ;;
                    esac
                    HEALTH_URL="http://localhost:${PORT}/health"
                    VERSION_URL="http://localhost:${PORT}/version"
                  fi

                  echo "Health check URL: $HEALTH_URL"

                  # Wait for service to be ready (max 5 minutes)
                  MAX_ATTEMPTS=30
                  ATTEMPT=0

                  while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
                    echo "Attempt $((ATTEMPT + 1))/$MAX_ATTEMPTS..."

                    HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$HEALTH_URL" || echo "000")

                    if [ "$HTTP_CODE" = "200" ]; then
                      echo "✅ Health check passed!"

                      # Verify version
                      VERSION_RESPONSE=$(curl -s "$VERSION_URL" || echo "{}")
                      echo "Version info: $VERSION_RESPONSE"

                      DEPLOYED_VERSION=$(echo "$VERSION_RESPONSE" | jq -r '.version // "unknown"')
                      EXPECTED_VERSION="<+pipeline.variables.VERSION>"

                      if [ "$DEPLOYED_VERSION" = "$EXPECTED_VERSION" ]; then
                        echo "✅ Version verified: $DEPLOYED_VERSION"
                      else
                        echo "⚠️  Version mismatch: expected $EXPECTED_VERSION, got $DEPLOYED_VERSION"
                      fi

                      exit 0
                    fi

                    echo "Health check returned HTTP $HTTP_CODE, retrying in 10s..."
                    sleep 10
                    ATTEMPT=$((ATTEMPT + 1))
                  done

                  echo "❌ Health check failed after $MAX_ATTEMPTS attempts"
                  exit 1
            environmentVariables: []
            outputVariables: []
          timeout: 10m

      # Step 5: Fetch Instance Script (required for CustomDeployment tracking)
      - step:
          type: FetchInstanceScript
          name: Fetch Instances
          identifier: Fetch_Instances
          spec:
            shell: Bash
            source:
              type: Inline
              spec:
                script: |-
                  #!/bin/bash
                  set -e

                  echo "=== Fetching Instance Information ==="

                  # Determine deployment target
                  DEPLOYMENT_TARGET="${DEPLOYMENT_TARGET:-aws}"

                  if [ "$DEPLOYMENT_TARGET" = "aws" ]; then
                    # AWS MODE - App Runner instance
                    INSTANCE_NAME="<+env.variables.app_runner_service_name>"
                    INSTANCE_URL="<+env.variables.app_runner_service_url>"

                    # Output instance in Harness format
                    echo "{\"instances\": [{\"instanceName\": \"${INSTANCE_NAME}\", \"instanceUrl\": \"${INSTANCE_URL}\"}]}"
                  else
                    # LOCAL MODE - Docker Compose container
                    CONTAINER_NAME="app-<+env.variables.environment>"

                    # Get container ID if running
                    CONTAINER_ID=$(docker ps -q -f name=${CONTAINER_NAME} || echo "unknown")

                    # Output instance in Harness format
                    echo "{\"instances\": [{\"instanceName\": \"${CONTAINER_NAME}\", \"instanceId\": \"${CONTAINER_ID}\"}]}"
                  fi
            outputVariables: []
            environmentVariables: []
          timeout: 5m

    stageType: Deployment
